import os
import numpy as np
import tensorflow as tf
import pandas as pd
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D, BatchNormalization
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import VGG16
from tensorflow.keras.regularizers import l2

# Set random seed for reproducibility
np.random.seed(42)
tf.random.set_seed(42)

# Define dataset path
base_path = '/content/drive/MyDrive/lung_cancer_model'  # Path to folder containing all images

# Image dimensions
IMG_WIDTH, IMG_HEIGHT = 128, 128

# Prepare dataframe for splitting
# Assuming the dataset has subfolders named after classes or a CSV file with labels
all_images = []
all_labels = []

# Example: Iterate through each class folder
for label in os.listdir(base_path):
    class_path = os.path.join(base_path, label)
    if os.path.isdir(class_path):  # Ensure it's a folder
        for img_file in os.listdir(class_path):
            all_images.append(os.path.join(class_path, img_file))
            all_labels.append(label)

# Create a dataframe
data = pd.DataFrame({
    'filepath': all_images,
    'label': all_labels
})

# Split data into train, validation, and test sets
train_df, test_df = train_test_split(data, test_size=0.2, stratify=data['label'], random_state=42)
train_df, valid_df = train_test_split(train_df, test_size=0.25, stratify=train_df['label'], random_state=42)

# Data augmentation and preprocessing
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    brightness_range=[0.8, 1.2],
    fill_mode='nearest'
)
valid_datagen = ImageDataGenerator(rescale=1./255)
test_datagen = ImageDataGenerator(rescale=1./255)

# Load data using flow_from_dataframe
train_generator = train_datagen.flow_from_dataframe(
    train_df,
    x_col='filepath',
    y_col='label',
    target_size=(IMG_WIDTH, IMG_HEIGHT),
    batch_size=32,
    class_mode='categorical'
)

validation_generator = valid_datagen.flow_from_dataframe(
    valid_df,
    x_col='filepath',
    y_col='label',
    target_size=(IMG_WIDTH, IMG_HEIGHT),
    batch_size=32,
    class_mode='categorical'
)

test_generator = test_datagen.flow_from_dataframe(
    test_df,
    x_col='filepath',
    y_col='label',
    target_size=(IMG_WIDTH, IMG_HEIGHT),
    batch_size=32,
    class_mode='categorical',
    shuffle=False  # Keep the order for evaluation
)

# Load pre-trained VGG16 model (without top layer)
base_model = VGG16(weights='imagenet', include_top=False, input_shape=(IMG_WIDTH, IMG_HEIGHT, 3))

# Fine-tune the base model
for layer in base_model.layers[:10]:
    layer.trainable = False

# Define the model
model = Sequential([
    base_model,  # Using pre-trained VGG16
    GlobalAveragePooling2D(),
    Dense(256, activation='relu', kernel_regularizer=l2(0.02)),
    BatchNormalization(),
    Dropout(0.4),
    Dense(128, activation='relu', kernel_regularizer=l2(0.02)),
    Dropout(0.3),
    Dense(len(train_generator.class_indices), activation='softmax')

])

# Compile the model
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])

# Callbacks
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6)

# Train the model
history = model.fit(
    train_generator,
    validation_data=validation_generator,
    epochs=25,
    callbacks=[early_stopping, lr_scheduler]
)

# Save the best model locally
model.save('best_lung_cancer_cnn_model.h5')

# Evaluate the model on the test set
test_loss, test_accuracy = model.evaluate(test_generator)
print(f"Test Accuracy: {test_accuracy:.2f}")

# Plot the training and validation accuracy
plt.figure(figsize=(12, 6))

# Accuracy Plot
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Training and Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

# Loss Plot
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

# Show the plots
plt.tight_layout()
plt.show()
