{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class MyImageDataGenerator(tf.keras.utils.Sequence):\n",
        "    def __init__(self, image_data_generator, **kwargs):\n",
        "        super().__init__()  # Call super().__init__() to avoid the warning\n",
        "        self.image_data_generator = image_data_generator\n",
        "        self.kwargs = kwargs\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_data_generator)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.image_data_generator[index]"
      ],
      "metadata": {
        "id": "79RB-WS3Ihv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from PIL import Image\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"Your `PyDataset` class should call `super().__init__\\\\(\\\\*\\\\*kwargs\\\\)`\")"
      ],
      "metadata": {
        "id": "kPkkhWnWIsVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCAfJn0GFQXM"
      },
      "outputs": [],
      "source": [
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Define dataset paths\n",
        "base_path = '/content/drive/MyDrive/LungcancerDataSet/Data'\n",
        "train_path = os.path.join(base_path, 'train')\n",
        "test_path = os.path.join(base_path, 'test')\n",
        "\n",
        "# Image dimensions\n",
        "IMG_WIDTH, IMG_HEIGHT = 128, 128\n",
        "\n",
        "# --- Data Cleaning: Verify and clean corrupted files ---\n",
        "def clean_data(directory):\n",
        "    for root, _, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            try:\n",
        "                img_path = os.path.join(root, file)\n",
        "                img = Image.open(img_path)\n",
        "                img.verify()  # Verify if the image is not corrupted\n",
        "            except (IOError, SyntaxError) as e:\n",
        "                print(f\"Removing corrupted file: {img_path}\")\n",
        "                os.remove(img_path)\n",
        "\n",
        "clean_data(train_path)\n",
        "clean_data(test_path)\n",
        "\n",
        "# --- Data Integration: Merge training and validation data ---\n",
        "# Merge train and validation into a single dataset for K-Fold Cross Validation\n",
        "filepaths = []\n",
        "labels = []\n",
        "for class_dir in os.listdir(train_path):\n",
        "    class_path = os.path.join(train_path, class_dir)\n",
        "    for file in os.listdir(class_path):\n",
        "        filepaths.append(os.path.join(class_path, file))\n",
        "        labels.append(class_dir)\n",
        "\n",
        "data = pd.DataFrame({\"filepaths\": filepaths, \"labels\": labels})\n",
        "\n",
        "# --- Data Augmentation and Normalization ---\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# --- Stratified 8-Fold Cross Validation ---\n",
        "X = data['filepaths']\n",
        "y = data['labels']\n",
        "\n",
        "kf = StratifiedKFold(n_splits=8, shuffle=True, random_state=42)\n",
        "fold_no = 1\n",
        "fold_results = []\n",
        "\n",
        "for train_index, val_index in kf.split(X, y):\n",
        "    print(f\"\\nTraining fold {fold_no}\")\n",
        "\n",
        "    # Create train and validation splits\n",
        "    train_data = data.iloc[train_index]\n",
        "    val_data = data.iloc[val_index]\n",
        "\n",
        "    train_generator = datagen.flow_from_dataframe(\n",
        "        train_data,\n",
        "        x_col='filepaths',\n",
        "        y_col='labels',\n",
        "        target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical'\n",
        "    )\n",
        "\n",
        "    val_generator = datagen.flow_from_dataframe(\n",
        "        val_data,\n",
        "        x_col='filepaths',\n",
        "        y_col='labels',\n",
        "        target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical'\n",
        "    )\n",
        "\n",
        "    # Load pre-trained VGG16 model\n",
        "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(IMG_WIDTH, IMG_HEIGHT, 3))\n",
        "\n",
        "    # Fine-tune VGG16\n",
        "    for layer in base_model.layers[:10]:\n",
        "        layer.trainable = False\n",
        "\n",
        "    # Define the model\n",
        "    model = Sequential([\n",
        "        base_model,\n",
        "        GlobalAveragePooling2D(),\n",
        "        Dropout(0.5),\n",
        "        Dense(256, activation='relu', kernel_regularizer=l2(0.02)),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.4),\n",
        "        Dense(128, activation='relu', kernel_regularizer=l2(0.02)),\n",
        "        Dropout(0.3),\n",
        "        Dense(64, activation='relu'),\n",
        "        #Access the number of classes using len(train_generator.class_indices)\n",
        "        Dense(len(train_generator.class_indices), activation='softmax')\n",
        "        ])\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Callbacks\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "    lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6)\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(\n",
        "        train_generator,\n",
        "        validation_data=val_generator,\n",
        "        epochs=25,\n",
        "        callbacks=[early_stopping, lr_scheduler]\n",
        "    )\n",
        "\n",
        "    # Save the model for the fold\n",
        "    model.save(f'best_lung_cancer_cnn_model_fold{fold_no}.h5')\n",
        "\n",
        "    # Evaluate on the validation set\n",
        "    val_loss, val_accuracy = model.evaluate(val_generator)\n",
        "    fold_results.append(val_accuracy)\n",
        "    print(f\"Fold {fold_no} Validation Accuracy: {val_accuracy:.2f}\")\n",
        "\n",
        "    # Plot training and validation accuracy/loss\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title(f'Training and Validation Accuracy (Fold {fold_no})')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Training Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title(f'Training and Validation Loss (Fold {fold_no})')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    fold_no += 1\n",
        "\n",
        "print(\"\\nK-Fold Cross-Validation Completed\")\n",
        "\n",
        "# Evaluate the final model on the test set\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_path,\n",
        "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "final_test_loss, final_test_accuracy = model.evaluate(test_generator)\n",
        "print(f\"Final Test Accuracy after K-Fold: {final_test_accuracy:.2f}\")\n",
        "\n",
        "# Generate predictions and classification report\n",
        "y_true = test_generator.classes\n",
        "y_pred_prob = model.predict(test_generator)\n",
        "y_pred = np.argmax(y_pred_prob, axis=1)\n",
        "\n",
        "# Classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "class_labels = list(test_generator.class_indices.keys())\n",
        "print(classification_report(y_true, y_pred, target_names=class_labels))\n",
        "\n",
        "# Confusion matrix\n",
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.imshow(conf_matrix, cmap='Blues', interpolation='nearest')\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.colorbar()\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.show()\n",
        "\n",
        "# Print average accuracy across folds\n",
        "print(f\"\\nAverage Validation Accuracy Across Folds: {np.mean(fold_results):.2f}\")\n"
      ]
    }
  ]
}